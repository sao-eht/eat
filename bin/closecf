#!/usr/bin/env python

# close ALIST and create HOPS control file steered to global solution
# 2016-10-11 Lindy Blackburn
# 2017-07-20 Lindy Blackburn & CK Chan - update for 2015+ data
# 2017-09-13 Lindy Blackburn, update for 2017 Rev1-Cal
# 2017-12-22 Lindy Blackburn, update for ER2
# 2021-05-15 Lindy Blackburn, legacy 2017 systematic errors

from eat.io import hops, util
from eat.hops import util as hu
import numpy as np
import pandas as pd
import argparse
import os
import sys
import datetime
import pwd

# logging
statline = '[%s] %s@%s:%s$ %s' % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            pwd.getpwuid(os.getuid())[0], os.uname()[1], os.getcwd(), ' '.join(sys.argv))

parser = argparse.ArgumentParser()
parser.add_argument('filename', help='alist txt file')
parser.add_argument('-de', '--delay_error', help='delay error systematic in [us]', type=float, default=2e-6)
parser.add_argument('-re', '--rate_error', help='rate error systematic in [ps/s]', type=float, default=1e-4)
# start with large 2ns delay systematic for delayed leakage, more realistic (2017) on-fringe systematic error is ~20ps
# the large error will effectively drive solution by parallel hands
parser.add_argument('-ce', '--crosspol_delay_error', help='additional systematic for cross pol delay added in quadrature', type=float, default=2e-3)
parser.add_argument('-sw', '--sigmas_to_window', help='sigmas to window for both delay and rate', type=float, default=0)
parser.add_argument('-dw', '--delay_window', help='fixed delay window to apply in [us]', type=float, default=0)
parser.add_argument('-rw', '--rate_window', help='fixed rate window to apply in [ps/s]', type=float, default=0)
parser.add_argument('-t', '--threshold', help='SNR cutoff threshold for detections', type=float, default=7.5)
parser.add_argument('-nf', '--no-fix', help='do not apply alist fixes', action="store_true")
args = parser.parse_args()

# read alist file (autodetect version 5 or 6)
a = util.noauto(hops.read_alist(args.filename))

# fix various polconvert errors
if not args.no_fix:
    util.fix(a)

# unwrap mbd to be aligned to sbd
util.unwrap_mbd(a)

# add delay and rate errors, with systematic limits on resolution
util.add_delayerr(a, mbd_systematic=args.delay_error, rate_systematic=args.rate_error,
                     crosspol_systematic=args.crosspol_delay_error)

# extra error for JS baseline, possible noise fringes, SR baseline, JR sideband contamination (rate), 1.5ns LMT delayed leakage, AR problem high band
iscross = a.polarization.isin({'RL', 'LR', 'XY', 'YX'})
ismixed = a.polarization.isin({'XR', 'XL', 'YR', 'YL', 'RX', 'LX', 'RY', 'LY'})

a['mbd_err'] = np.sqrt(a['mbd_err']**2
                       + 1.*(a.baseline.isin({'SR', 'RS'})) + 1.*(a.snr < args.threshold)          # potentially bogus fringes
                       + 50e-6**2*((a.year == '2017') & a.baseline.isin({'JS', 'JR', 'SJ', 'RJ'})) # 2017 JS sideband contamination
                       + 1.5e-3**2*((a.year == '2017') & a.baseline.str.contains('L') & iscross)   # 2017 LMT reflected leakage
                       + 23.e-3**2*((a.year == '2017') & (a.ref_freq > 228100.) & (a.baseline == 'AR') & (a.polarization == 'RL')
                         & (a.scan_id.isin({'095-0829', '095-0839', '095-0849', '095-0859', '095-0908'}))) # 2017 high band AR outliers
                       + 8.5e-3**2*((a.year == '2018') & a.baseline.str.contains('X') & iscross)  # 2018 APEX delayed leakage various
                       + 0.5e-3**2*((a.expt_no == '3649') & a.baseline.str.contains('A') & iscross) # 2018 poor polconvert 3649 (118)
                       + 8.5e-3**2*((a.expt_no == '3644') & (a.baseline == 'AL') & (a.polarization == 'LR') & (a.scan_id == '111-0359')) 
                       + 4.5e-3**2*((a.expt_no == '3644') & (a.baseline == 'AZ') & (a.polarization == 'RL') & (a.scan_id == '111-0813'))
                      )

a['rate_err'] = np.sqrt(a['rate_err']**2
                        + 0.25*(a.baseline.isin({'SR', 'RS'})) + 4.0*(a.baseline.isin({'JR', 'RJ'})) + 1.*(a.snr < args.threshold))

hu.closefringe(a)

# print out FF control file

print('* ' + statline)
g = a.groupby('timetag')
for (scan, b) in g:
#     sites = set(chain(*b.baseline))
#     for site in sites:
#         # this may still accept some unconnected baselines
#         snrmax = b[b.baseline.str.contains(site)].snr.max()
#         if snrmax < args.threshold:
#             print("if scan %s and station %s skip true * maxsnr %.1f" % (scan, site, snrmax))
    # sets of connected groups of sites for scan based on good detections
    connected = hu.fringegroups(b[b.snr >= args.threshold].baseline)
    for c in b.groupby('baseline').first().reset_index().itertuples():
        # hack fix for fourfit issue on one scan with X VEX start offset
        if c.year == '2017' and c.timetag == '097-051800' and 'X' in c.baseline:
            timetag = '097-051850'
        else:
            timetag = c.timetag
        if any((c.baseline[0] in sites and c.baseline[1] in sites for sites in connected)):
            print("if scan %s and baseline %s sb_win %10.7f %10.7f mb_win %10.7f %10.7f dr_win %15.12f %15.12f * %s %-4s expt_no %d" %
                (timetag, c.baseline, c.mbd_unwrap, c.mbd_unwrap, c.mbdelay, c.mbdelay, 1e-6*c.delay_rate, 1e-6*c.delay_rate,
                 c.source, 'GOOD' if c.success else 'BAD', c.expt_no))
        else:
            print("if scan %s and baseline %s skip true * expt_no %d snr %.1f" % (timetag, c.baseline, c.expt_no, c.snr))

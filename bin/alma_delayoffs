#!/usr/bin/env python

# evaluate R-L delay offsets for sites using ALMA as reference
# 2017-09-15 Lindy Blackburn

from eat.io import hops, util
from eat.hops import util as hu
import pandas as pd
import numpy as np
import sys
import re
import argparse
import os
import datetime
import pwd

# logging
statline = '[%s] %s@%s:%s$ %s' % (datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'), pwd.getpwuid(os.getuid())[0], os.uname()[1], os.getcwd(), ' '.join(sys.argv))

# systematics parameters
sys_fac = 1.0 # systematic factor on thermal delay error
sys_par = 2e-6 # 2 ps on fringe delay
sys_cross = 20e-6 # 20 ps on cross hand delay

# special segments list of restarts in days since year
# restarts = {'X':map(util.tt2dt, ['101-003000'])} # just before M87 scan
restarts = hu.restarts_2018

parser = argparse.ArgumentParser()
parser.add_argument('filename', help='alist txt file')
parser.add_argument('-n', '--nchan', help='number of channels', nargs='?', type=int, default=32)
parser.add_argument('-o', '--outfile', help='output csv filename', type=str, default=None)
parser.add_argument('-c', '--controlcodes', help='construct control codes rather than csv table', action='store_true', default=False)
parser.add_argument('-de', '--delay_error', help='delay error systematic in [us]', type=float, default=2e-6)
parser.add_argument('-re', '--rate_error', help='rate error systematic in [ps/s]', type=float, default=1e-3)
parser.add_argument('-ce', '--crosspol_delay_error', help='additional systematic for cross pol delay added in quadrature', type=float, default=20e-6)
parser.add_argument('-r', '--ref', help='reference polarization', default='L')
parser.add_argument('-m', '--mixed', help='handle and average ALMA mixed pol (ALMA must be first station)', action='store_true', default=False)
parser.add_argument('-nf', '--no-fix', help='do not apply alist fixes', action="store_true")
args = parser.parse_args()

# read alist file (autodetect version 5 or 6)
a = util.noauto(hops.read_alist(args.filename))
if not args.no_fix:
    util.fix(a) # fix various polconvert errors

a = a[(a.snr > 9) & (a.baseline.str[0] == 'A')]
nchan = a.freq_code.str[1:].astype(int).max()

# add delay and rate errors, with systematic limits on resolution
util.add_delayerr(a, mbd_systematic=args.delay_error, rate_systematic=args.rate_error,
                     crosspol_systematic=args.crosspol_delay_error)

# handle mixed pols
if args.mixed:
    a['ref_pol'] = a.polarization.str.get(0)
    a['polarization'] = a.polarization.map({'XL':'LL', 'YL':'LL', 'XR':'RR', 'YR':'RR'})
    index="ref_freq expt_no scan_id scan_no source timetag ref_pol".split()
else:
    index="ref_freq expt_no scan_id scan_no source timetag".split()

# RRLL stats after segmentation
(p, stats) = hu.rrll_segmented(a, restarts=restarts, index=index)

# make delay out table
offs = stats.reset_index()
offs['site'] = offs.baseline.str[1]
offs['LR_delay'] = offs.LLRR_mean
offs['LR_delay_err'] = offs.LLRR_sys

if args.outfile == None:
    out = sys.stdout
else:
    out = open(args.outfile, 'w')

if args.controlcodes:
    out.write('* ' + statline + '\n')
    cflines = offs.apply(hu.doff2cf, axis=1, args=(nchan, args.ref))
    out.write(''.join(cflines))
else:
    offs["start stop site LR_delay LR_delay_err".split()].to_csv(out, float_format='%+9.7f', index=False)


#!/usr/bin/env python
#
# Use ALMA to reference phase-cal phases and delay offsets
# 2017-11-22 Chi-kwan Chan (move from pipeline to EAT)
# 2017-12-28 CKC major update to simplify pipelining

from __future__ import print_function

import datetime, string
import pwd, os, sys
import argparse

import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import matplotlib.cm     as cm

import pandas as pd
import numpy  as np
from scipy import interpolate

from eat.io   import hops, util
from eat.hops import util as hu

#==============================================================================
# Helper functions

def unwrap(phi):
    """Unwrap an array of angles to avoid artificial jumps due to branching
    """
    for i in np.arange(len(phi)-1)+1:
        if   phi.iloc[i] - phi.iloc[i-1] >  180: phi.iloc[i:] -= 360
        elif phi.iloc[i] - phi.iloc[i-1] < -180: phi.iloc[i:] += 360
    return phi

def offset(phi):
    """Offset an array of angles (in degree) to the principle branch
    """
    while True:
        m = np.mean(phi)
        if   m >  180: phi -= 360
        elif m < -180: phi += 360
        else         : break
    return phi

def load(file):
    """Read an alist file and prepare phases phase-cal

    Read an alist file, apply filter to select the userful rows, and
    then access the corel (per-channel) phases for performing
    phase-cal.
    """
    a = util.noauto(hops.read_alist(file))
    if not args.no_fix:
        util.fix(a) # fix various polconvert errors

    # Apply row filtering
    a = a[a.snr > 50]
    a = a[a.baseline.str.contains(args.reference)] # must contain ALMA (or ref station)
    a = a[(a.polarization == 'LL')|
          (a.polarization == 'RR')|
          (a.polarization == 'XR')|
          (a.polarization == 'XL')|
          (a.polarization == 'YR')|
          (a.polarization == 'YL')]
    a = a.reset_index(drop=True)
    util.add_path(a)

    # grab channel separation, needed since alist amb is insufficient precision
    par = hu.params(a.iloc[0].path)
    d_nu = 1e6 * np.diff(np.sort(par.fedge))[0] # par.fedge in MHz
    a['d_nu'] = d_nu

    # TODO: obtain chan_ids from the control files / fringe files / user
    # Access corel (per-channel) visibility
    dflist = []
    for i, f in a.path.items():
        par = hu.params(f)

        # perform quick adhoc phase correction and obtain a single averaged value
        v = hu.adhoc(f, roundrobin=False).vcorr.mean(axis=0)
        p = np.angle(np.mean(v))

        # compute vis
        vis = v * np.exp(-1j * p)

        # if ALMA (or ref) is not the reference, reverse baseline label and negate vis
        b = a.baseline[i]
        if b[1] == args.reference:
            a.loc[i, 'baseline'] = b[::-1]
            vis = np.conj(vis)
            print("WARNING: ALMA (or args.reference) is not the reference", file=sys.stderr)

        # construct temp dataframe
        # TODO: add metadata from a to tempdf here and avoid concatenating at the very end
        tempdf = pd.DataFrame(vis[np.newaxis,:], columns=par.fedge)
       
        #tempdf = pd.concat((a[a['path']==f][extractcols], tempdf), axis=1) # add metadata from DataFrame a
        dflist.append(tempdf)

    df = pd.concat(dflist)
    df = df.reset_index(drop=True)
    df = df.sort_index(axis=1)
    df.columns = list(string.ascii_letters[:df.columns.shape[0]]) # assign ASCII channel codes to frequencies

    # add metadata from a to df
    extractcols  = ['polarization', 'baseline', 'quality', 'snr', 'resid_phas', 'd_nu'] # metadata cols to extract from DataFrame a
    return pd.concat([a[extractcols], df], axis=1)


def qfit(y1, y2, y3):
    """Quadratic fits
    """
    a  =       y1
    b  = (-3.0*y1 + 4.0*y2 - y3) / 2.0
    c  = (     y1 - 2.0*y2 + y3) / 2.0
    return a, b, c

def fix_nan(y):
    """Extrapolation for last channel
    """
    a, b, c = qfit(y[:,-4], y[:,-3], y[:,-2])
    last    = a + 3.0*b + 9.0*c # == a + b x + c x**2 at x == 3
    m       = np.isnan(y[:,-1])
    y[m,-1] = last[m]
    return y

def fix_nan_v2(y):
    """
    Extrapolate for missing channels
    """
    nbl = y.shape[0]
    nchan = y.shape[1]
    for ii in np.arange(nbl):
        ind = np.where(~np.isnan(y[ii,:]))[0] # get first element (np.ndarray) of returned tuple
        f = interpolate.interp1d(ind, y[ii,ind], kind='linear', bounds_error=False, fill_value='extrapolate')
        y[ii,:] = f(np.arange(nchan)) # apply f to the entire array to extrapolate

    return y

def derivative(y, dx=1.0):
    """Compute derivative of y
    """
    a, b, c = qfit(y[:,-3], y[:,-2], y[:,-1])
    m1 = b + 4.0*c # == b + 2 c x with x == 2
    a, b, c = qfit(y[:,0], y[:,1], y[:,2])
    m0 = b         # == b + 2 c x with x == 0
    return np.concatenate((np.reshape(m0, (-1,1)),
                           0.5 * (y[:,2:] - y[:,:-2]),
                           np.reshape(m1, (-1,1))),
                          axis=1) / dx

def mkcf(baselines, code, data):
    sites = [b[1] for b in baselines]
    chans = string.ascii_letters[:data.shape[1]]
    return ["""if station {}
  {} {}
    {}
""".format(s, code, chans, " ".join(["{:.6f}".format(p) for p in -data[i,:]]))
            for i, s in enumerate(sites)]

def mkcsv(baselines, data, file):
    out = pd.DataFrame(data)
    out.insert(0, 'label', baselines)
    out.to_csv(file, index=False, header=False, sep=" ", float_format="%.9g")

def mkplot(baselines, phases, slopes, file):
    cs = cm.rainbow(np.linspace(0,1,len(baselines)))
    d  = np.array([-0.5,0.5])
    x  = np.arange(phases.shape[1])
    plt.figure()
    for i, b in enumerate(baselines):
        y = -phases[i,:]
        m = -slopes[i,:]
        plt.scatter(x, y, color=cs[i], label=b)
        for j in x:
            plt.plot(x[j]+d, y[j]+d*m[j], color=cs[i])
    plt.legend()
    if "." in file:
        plt.savefig(file)
    else:
        plt.show()

#==============================================================================
# Main code
#------------------------------------------------------------------------------
# Logging
statline = "[{}] {}@{}:{}$ {}".format(
    datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
    pwd.getpwuid(os.getuid())[0], os.uname()[1], os.getcwd(),
    ' '.join(sys.argv))

#------------------------------------------------------------------------------
# Argument parsing
try:
    datadir = os.environ['DATADIR']
except:
    datadir = None

parser = argparse.ArgumentParser(
    description="Estimate phase-cal phases and delay offsets")
parser.add_argument("filename",
                    help="alist file")
parser.add_argument("-d", "--datadir", default=datadir,
                    help="use fringe files from this data directory")
parser.add_argument("-a", "--average", default=False, action="store_true",
                    help="use average L and R phase cal")
parser.add_argument("-o", "--outfile", default=[sys.stdout], nargs="+",
                    help="output file name(s); "+
                         "if \"-c\" is used, only 1 file name is allowed; "+
                         "otherwise, at most 5 names can be used")
parser.add_argument("-c", "--controlcodes", default=False, action="store_true",
                    help="construct control codes rather than csv table")
parser.add_argument("-g", "--graph",        default=False, action="store_true",
                    help="graphic output")
parser.add_argument("-r", "--reference", default='A',
                    help="use a different reference antenna from ALMA")
parser.add_argument('-nf', '--no-fix', help='do not apply alist fixes', action="store_true")
args = parser.parse_args()

if len(args.outfile) > 5:
    print("At most 4 output files are supported")
    exit(1)
elif args.controlcodes and len(args.outfile) != 1:
    print("Only 1 output file is supported when \"--controlcodes\" is set")
    exit(1)

#------------------------------------------------------------------------------
# Get data, perform phase cal, and compute delay offsets
if args.datadir is not None:
    hu.set_datadir(args.datadir)

df = load(args.filename)
rr = df[df.polarization.str[1] == 'R'] # support mixed products: RR, XR, YR
ll = df[df.polarization.str[1] == 'L']

nchan = string.ascii_letters.find(df.columns[-1]) + 1
chans = list(string.ascii_letters[:nchan])

# at some point, pandas.core.groupby.GroupBy.mean() no longer considers numpy.complex128 to be numeric type (?!!)
# update: previous issue may be related to change in numeric_only default handling in 1.3.0
# https://github.com/pandas-dev/pandas/issues/42395
# however as of 1.3.4 groupby aggregation functions are now completely broken for complex values
# including simple aggregation such as "first()"
# https://github.com/pandas-dev/pandas/issues/43701
# here we could replace "mean" with "sum" -- which for some reason still works
# but since groupby operations on complex values are so common, may want to simply revert pandas
pcf   = df.groupby('baseline')[chans].sum(numeric_only=False).apply(np.angle, deg=True)
pcr   = rr.groupby('baseline')[chans].sum(numeric_only=False).apply(np.angle, deg=True)
pcl   = ll.groupby('baseline')[chans].sum(numeric_only=False).apply(np.angle, deg=True)

pcf[:] = fix_nan_v2(pcf.apply(unwrap, axis=1).apply(offset, axis=1).values)
pcr[:] = fix_nan_v2(pcr.apply(unwrap, axis=1).apply(offset, axis=1).values)
pcl[:] = fix_nan_v2(pcl.apply(unwrap, axis=1).apply(offset, axis=1).values)

slopes = derivative(pcf.values)
# d_nu   = 58.59375e6 # hard wire separation between channels
d_nu   = df['d_nu'][0] # grab the first saved d_nu
delays = 1e9 * (slopes / 360.0) / d_nu # in nanosecond

#------------------------------------------------------------------------------
# Outputs
if args.controlcodes:
    need_open_close = not hasattr(args.outfile[0], "write")
    if need_open_close:
        f = open(args.outfile[0], "w")
    else:
        f = args.outfile[0]
    f.write("* {}\n\n".format(statline))
    if args.average:
        f.write("\n".join(mkcf(pcr.index.values, "pc_phases", pcf.values) +
                          mkcf(pcf.index.values, "delay_offs",  delays)))
    else:
        f.write("\n".join(mkcf(pcr.index.values, "pc_phases_r", pcr.values) +
                          mkcf(pcl.index.values, "pc_phases_l", pcl.values) +
                          mkcf(pcf.index.values, "delay_offs",  delays)))
    if need_open_close:
        f.close()
else:
    k = list("rlfds")
    b = {'r': pcr.index.values,
         'l': pcl.index.values,
         'f': pcf.index.values,
         'd': pcf.index.values,
         's': pcf.index.values}
    v = {'r': pcr.values,
         'l': pcl.values,
         'f': pcf.values,
         'd': delays,
         's': slopes}
    if len(args.outfile) == 1:
        f = args.outfile[0]
        if hasattr(f, "write"):
            for j in k:
                mkcsv(b[j], v[j], f)
        else:
            p, x = os.path.splitext(f)
            for j in k:
                mkcsv(b[j], v[j], p+'_'+j+x)
    else:
        for i, f in enumerate(args.outfile):
            mkcsv(b[k[i]], d[k[i]], f)

if args.graph:
    k = pcf.index.values
    mkplot(pcf.index.values, pcf.values, slopes,      "pc_phase_f.pdf")

    i = [np.where(k == b)[0][0] for b in pcr.index.values]
    mkplot(pcr.index.values, pcr.values, slopes[i,:], "pc_phase_r.pdf")

    i = [np.where(k == b)[0][0] for b in pcl.index.values]
    mkplot(pcl.index.values, pcl.values, slopes[i,:], "pc_phase_l.pdf")
